{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-27T00:40:37.303213Z",
     "start_time": "2025-04-27T00:40:37.295711Z"
    }
   },
   "source": [
    "#Reference\n",
    "\n",
    "#https://python.langchain.com/docs/tutorials/rag/\n",
    "#https://www.youtube.com/watch?v=yF9kGESAi3M&t=3823s\n",
    "\n",
    "\n",
    "#The RAG has two main components\n",
    "\n",
    "#Indexing - taking data from source and indexing it , happens offline\n",
    "# in other words ,\n",
    "# (Document Loaders) take/load data\n",
    "# (Text Splitters) break it down to chunks\n",
    "# (Embedding model)convert the chunks to embeddings\n",
    "# (Vector store)store the data inform of embeddings\n",
    "\n",
    "#Retrieval- the RAG chain, takes user query at runtime, retrieves relevant data from index, then passes to the model\n",
    "# will be in more detail in RAG part b\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T00:40:41.531902Z",
     "start_time": "2025-04-27T00:40:41.472650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# select chatmodel\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from textdistance import overlap\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm=init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n"
   ],
   "id": "3e0595fd8c4eaaac",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T00:40:48.260186Z",
     "start_time": "2025-04-27T00:40:45.661337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#having issue with openai embedding\n",
    "#from langchain_openai import OpenAIEmbeddings\n",
    "#embeddings=OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "#replaced it with hugging face embedding\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
   ],
   "id": "3ecbbbf307da17b8",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T00:39:07.033947Z",
     "start_time": "2025-04-27T00:39:07.020290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#tried using vector stores,inmemory, had issues when i tried to implement it like this\n",
    "# hence used FAISS\n",
    "#from langchain_core.vectorstores import InMemoryVectorStore\n",
    "#vector_store=InMemoryVectorStore(embeddings)\n"
   ],
   "id": "3fec83ab71337c2f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T00:39:12.473588Z",
     "start_time": "2025-04-27T00:39:12.159423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "# we will receive a html file\n",
    "# we are going to select only title, header and content  from the html\n",
    "bs4_strainer=bs4.SoupStrainer(class_=(\"post-title\",\"post-header\",\"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs=loader.load()\n",
    "assert len(docs)==1\n",
    "print(f\"Total document length(characters) {len(docs[0].page_content)}\")"
   ],
   "id": "c4c4191c40f6b9a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total document length(characters) 43130\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T00:39:16.462917Z",
     "start_time": "2025-04-27T00:39:16.456603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#spliting the document for vector storage\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "all_splits=text_splitter.split_documents(docs)\n",
    "print(len(all_splits))\n",
    "print(all_splits[0])\n",
    "#print(len(all_splits[65]))\n"
   ],
   "id": "641a41b050e92c83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "page_content='LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory' metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 8}\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T00:39:27.646548Z",
     "start_time": "2025-04-27T00:39:22.273914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "vector_store = FAISS.from_documents(documents=all_splits, embedding=embeddings)\n",
    "#storing documents\n",
    "document_ids=vector_store.add_documents(documents=all_splits)\n",
    "print(document_ids[0:5])"
   ],
   "id": "60faad216724b7bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['442dd2f0-d4ad-4feb-a19a-93c500e18364', 'cc2acfd3-3484-4b62-92f8-2e91baafb755', 'edf331ca-29c0-4666-be47-0f219d4cdb33', 'aa05f05c-e3fd-4893-9307-23dd1a2b0787', 'e7f253c2-9f38-44ba-9fb6-a96f3f98f35a']\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
